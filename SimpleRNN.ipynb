{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffea04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential  # \n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b98ee85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (25000,), Training labels shape: (25000,)\n",
      "Testing data shape: (25000,), Testing labels shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the IMDB dataset \n",
    "\n",
    "max_features = 100000 # initialie my vocabulary size. \n",
    "(x_train, y_train),(x_test,y_test)=imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Print the shape of the data \n",
    "print(f\"Training data shape: {x_train.shape}, Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing data shape: {x_test.shape}, Testing labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "176706b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample review (as integers): [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "Sample lavel : 1\n"
     ]
    }
   ],
   "source": [
    "# Inspect a sample review and its label \n",
    "# Sample label comming 1 means true and 0 means false. \n",
    "sample_review =  x_train[0]\n",
    "sample_label = y_train[0]\n",
    "\n",
    "print(f\"Sample review (as integers): {sample_review}\")\n",
    "print(f\"Sample lavel : {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd11c2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    19,   178,    32],\n",
       "       [    0,     0,     0, ...,    16,   145,    95],\n",
       "       [    0,     0,     0, ...,     7,   129,   113],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     4,  3586, 22459],\n",
       "       [    0,     0,     0, ...,    12,     9,    23],\n",
       "       [    0,     0,     0, ...,   204,   131,     9]],\n",
       "      shape=(25000, 500), dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sequence , we are going to do the padding and set a max words in a sentence. \n",
    "from tensorflow.keras.preprocessing import sequence \n",
    "\n",
    "max_words = 500\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = max_words)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = max_words)\n",
    "x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7ba12ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     1,    14,    22,    16,    43,   530,\n",
       "         973,  1622,  1385,    65,   458,  4468,    66,  3941,     4,\n",
       "         173,    36,   256,     5,    25,   100,    43,   838,   112,\n",
       "          50,   670, 22665,     9,    35,   480,   284,     5,   150,\n",
       "           4,   172,   112,   167, 21631,   336,   385,    39,     4,\n",
       "         172,  4536,  1111,    17,   546,    38,    13,   447,     4,\n",
       "         192,    50,    16,     6,   147,  2025,    19,    14,    22,\n",
       "           4,  1920,  4613,   469,     4,    22,    71,    87,    12,\n",
       "          16,    43,   530,    38,    76,    15,    13,  1247,     4,\n",
       "          22,    17,   515,    17,    12,    16,   626,    18, 19193,\n",
       "           5,    62,   386,    12,     8,   316,     8,   106,     5,\n",
       "           4,  2223,  5244,    16,   480,    66,  3785,    33,     4,\n",
       "         130,    12,    16,    38,   619,     5,    25,   124,    51,\n",
       "          36,   135,    48,    25,  1415,    33,     6,    22,    12,\n",
       "         215,    28,    77,    52,     5,    14,   407,    16,    82,\n",
       "       10311,     8,     4,   107,   117,  5952,    15,   256,     4,\n",
       "       31050,     7,  3766,     5,   723,    36,    71,    43,   530,\n",
       "         476,    26,   400,   317,    46,     7,     4, 12118,  1029,\n",
       "          13,   104,    88,     4,   381,    15,   297,    98,    32,\n",
       "        2071,    56,    26,   141,     6,   194,  7486,    18,     4,\n",
       "         226,    22,    21,   134,   476,    26,   480,     5,   144,\n",
       "          30,  5535,    18,    51,    36,    28,   224,    92,    25,\n",
       "         104,     4,   226,    65,    16,    38,  1334,    88,    12,\n",
       "          16,   283,     5,    16,  4472,   113,   103,    32,    15,\n",
       "          16,  5345,    19,   178,    32], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking whether the padding happend the x_train or not. [ pre-padding  ] \n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4812f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple RNN \n",
    "# 128 is a dimension set for the feature representation of the data. \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,128,input_length= max_words))   ## embedding layer - responsible for converting rhe text to the vectors for the mentioned dimensions. \n",
    "model.add(SimpleRNN(128,activation='relu'))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a774891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line tells the model the input shape and max_words set for the RNN model to be trained in the shape defined in the above code. \n",
    "model.build(input_shape=(None, max_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3286d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,800,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m12,800,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,833,025</span> (48.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,833,025\u001b[0m (48.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,833,025</span> (48.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,833,025\u001b[0m (48.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b6f4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34c64f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating an Instances of Early stoping callback \n",
    "## We are setting Early stopping Callback so that the while training on the such a large data and dimension mentioned. It sopping after patience of 5.\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystopping = EarlyStopping(monitor = 'val_loss', patience=5,restore_best_weights='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8f4271f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 90ms/step - accuracy: 0.6747 - loss: 16072.2363 - val_accuracy: 0.8004 - val_loss: 0.4462\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 87ms/step - accuracy: 0.8561 - loss: 0.3689 - val_accuracy: 0.7588 - val_loss: 0.4983\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 91ms/step - accuracy: 0.9294 - loss: 0.1964 - val_accuracy: 0.8400 - val_loss: 0.4068\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 86ms/step - accuracy: 0.9654 - loss: 0.1006 - val_accuracy: 0.8380 - val_loss: 0.5138\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 89ms/step - accuracy: 0.9833 - loss: 0.0536 - val_accuracy: 0.8494 - val_loss: 0.6479\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 88ms/step - accuracy: 0.9832 - loss: 0.0558 - val_accuracy: 0.8298 - val_loss: 0.6849\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 90ms/step - accuracy: 0.9830 - loss: 0.0532 - val_accuracy: 0.8304 - val_loss: 0.8125\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 92ms/step - accuracy: 0.9873 - loss: 0.0474 - val_accuracy: 0.8094 - val_loss: 0.6935\n"
     ]
    }
   ],
   "source": [
    "# Train the model with earlystopping \n",
    "\n",
    "History = model.fit(\n",
    "    x_train,y_train,epochs=10,batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks = [earlystopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a37264c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# save my model file \n",
    "model.save('SimpleRNN_IMDB.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3639ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
